{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g88HgXnuUtV1"
   },
   "source": [
    "# Duboko učenje - laboratorijska vježba - generativni modeli - Generative asdversarial networks (GAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZMiK8Z1xUtV2"
   },
   "source": [
    "Primarna namjena GAN-a je isto generiranje novih i uvjerljivih uzoraka, no princip rada je malo drugačiji od prethodna dva modela. GAN ne procjenjuje direktno parametre $p(\\mathbf x)$ ili bilo koje druge distribucije, premda se njegovo treniranje može interpretirati kao estimacija $p(\\mathbf x)$. Najvjerojatnije zahvaljujući tom drugačijem pristupu, GAN-ovi često generiraju vizualno najbolje uzorke u usporedbi sa VAE ili drugim generativnim mrežama.\n",
    "\n",
    "GAN se sastoji od dvije zasebne mreže \n",
    "\n",
    "1. Generator (G) koji ima zadatak generirati uvjerljive uzorke\n",
    "2. Diskriminator (D) koji ima zadatak prepoznati radi li se o pravom uzorku (iz skupa za trniranje) ili lažnom uzorku koji je generirao G\n",
    "\n",
    "<center>\n",
    "<div class=\"fig figcenter fighighlight\">\n",
    "  <img src=\"https://dlunizg.github.io/assets/lab4/GAN.svg\" width=\"30%\">\n",
    "</div>\n",
    "</center>\n",
    "\n",
    "Te dvije mreže su protivnici (Adversaries), imaju dijametralno suprotstavljene ciljeve te se pokušavaju nadmudriti. To nadmetanje ih tjera da budu sve bolji u postizanju svog cilja i da se fokusiraju na sve bitne detalje ulaznih podataka. Očekivano, njihovo nadmetanje trebalo bi dovesti do toga da generator generira savršene uzorke koje diskriminator ne može razlikovati od uzoraka iz skupa za treniranje. Da bi generator postigao takav uspjeh nužno je da i diskriminator bude maksimalno dobar u svom zadatku.\n",
    "\n",
    "Generator na svojem izlazu generira uzorke za neki slučajni ulazni vektor koji prati neku distribuciju. Ta slučajnost na ulazu omogućuje generatoru da uvijek generira nove uzorke. Pri tome nema nekih posebnih ograničenja na arhitekturu generatora, no poželjno je da se može trenirati backpropagation algoritmom. \n",
    "\n",
    "<center>\n",
    "<div class=\"fig figcenter fighighlight\">\n",
    "  <img src=\"https://dlunizg.github.io/assets/lab4/G.svg\" width=\"30%\">\n",
    "</div>\n",
    "</center>\n",
    "\n",
    "Diskriminator na svome izlazu treba estimirati pripadnost razredu stvarnih ili lažnih uzoraka za svaki ulazni vektor. Za razliku od generatora, ovdje je moguće koristiti učenje pod nadzorom jer se za svaki uzorak zna da li je došao iz skupa za treniranje ili od generatora. Radi jednostavnosti možemo izlaz diskriminatora ograničiti u rasponu $[0,1]$ i interpretirati kao vjerojatnost da je ulazni uzorak stvaran (iz skupa za treniranje).\n",
    "\n",
    "    \n",
    "<center>\n",
    "<div class=\"fig figcenter fighighlight\">\n",
    "  <img src=\"https://dlunizg.github.io/assets/lab4/D.svg\" width=\"30%\">\n",
    "</div>\n",
    "</center>\n",
    "    \n",
    "\n",
    "Gore opisani ciljevi diskriminatora i generatora mogu se formalno izraziti u sljedećoj funkciji cilja:\n",
    "\n",
    "$\\min_G \\max_D V(D,G) = E_{ \\mathbf x \\sim p_{data}(\\mathbf x) } [\\log D( \\mathbf x)] + E_{ \\mathbf z  \\sim p_{\\mathbf z}(\\mathbf z) } [\\log(1 - D(G( \\mathbf z)))]$\n",
    "\n",
    "Prvi pribrojnik predstavlja očekivanje procjene log vjerojatnosti da su uzorci iz skupa za treniranje stvarni. Drugi pribrojnik predstavlja očekivanje procjene log vjerojatnosti da generirani uzorci nisu stvarni, tj. da su umjetni. Diskriminator ima za cilj maksimizirati oba pribrojnika, dok generator ima za cilj minimizirati drugi pribrojnik. Svaki pribrojnik funkcije cilja može se jednostavno procijeniti za jednu mini grupu te se može procijeniti gradijent s obzirom na prametre obiju mreža. \n",
    "\n",
    "Treniranje dviju mreža (G i D) može se provesti istovremeno ili se u jednoj iteraciji prvo može trenirati jedna mreža a zatim druga. Dodatno, neki autori preporučuju da se u nekoliko uzastopnih iteracija trenira jedna mreža, a nakon toga druga mreža samo jednu iteraciju.\n",
    "\n",
    "    \n",
    "<center>\n",
    "<div class=\"fig figcenter fighighlight\">\n",
    "  <img src=\"https://dlunizg.github.io/assets/lab4/GAN2.svg\" width=\"50%\">\n",
    "</div>\n",
    "</center>\n",
    "\n",
    "\n",
    "Kod generiranja slika uspješnim se pokazao Deep Convolutional GAN (DCGAN) koji u skrivenim slojevima obiju mreža koristi konvolucijske slojeve. Za razliku od klasičnih konvolucijskih mreža, ovdje se ne koriste pooling slojevi nego se uzorkovanje provodi pomoću konvolucijskih slojeva koji imaju posmak veći od 1. Autori mreže preporučuju korištenje Batch normalizacije u svim slojevima osim u izlaznom sloju generatora te ulaznom i izlaznom sloju diskriminatora. Korištenje Leaky ReLU aktivacijskih funkcija u svim slojevima osim u izlaznim je još jedna specifičnost DCGAN-a kao i eliminacija potpuno povezanih slojeva.\n",
    "\n",
    "    \n",
    "<center>\n",
    "<div class=\"fig figcenter fighighlight\">\n",
    "  <img src=\"https://dlunizg.github.io/assets/lab4/DCGAN.svg\" width=\"50%\">\n",
    "</div>\n",
    "</center>\n",
    "\n",
    "### U sljedećih nekoliko blokova koda nalaze se inicijalizacijske postavke i gotove pomoćne funkcije"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 472,
     "status": "ok",
     "timestamp": 1623409458973,
     "user": {
      "displayName": "Filip Todorić",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiH7DuUBhcAqaYzLq0j65wQZ4SfN8adz357E-Tp=s64",
      "userId": "01972315933449635735"
     },
     "user_tz": -120
    },
    "id": "6of1WViKUtV6"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "import tqdm\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "import torch.distributions as tdist\n",
    "\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1623409459718,
     "user": {
      "displayName": "Filip Todorić",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiH7DuUBhcAqaYzLq0j65wQZ4SfN8adz357E-Tp=s64",
      "userId": "01972315933449635735"
     },
     "user_tz": -120
    },
    "id": "vI3Eo32_UtV9"
   },
   "outputs": [],
   "source": [
    "def prepare_data_loaders(batch_size=32):\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.MNIST('./files', train=True, download=True,\n",
    "                               transform=torchvision.transforms.Compose([\n",
    "                                   torchvision.transforms.Resize(64),\n",
    "                                   torchvision.transforms.ToTensor()\n",
    "                               ])), batch_size=batch_size)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        torchvision.datasets.MNIST('./files', train=False, download=True,\n",
    "                                   transform=torchvision.transforms.Compose([\n",
    "                                       torchvision.transforms.Resize(64),\n",
    "                                       torchvision.transforms.ToTensor()\n",
    "                                   ])), batch_size=batch_size)\n",
    "    \n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yNj1R-q3UtV9"
   },
   "source": [
    "### 5. Zadatak\n",
    "\n",
    "Implementirajte DCGAN s generatorom i diskriminatorom. Arhitekura treba biti:\n",
    "    \n",
    "* Generator\n",
    "    * Sloj 1 - Broj izlaznih kanala = 512, veličina jezgre = 4, veličina koraka = 1\n",
    "    * Sloj 2 - Broj izlaznih kanala = 256, veličina jezgre = 4, veličina koraka = 2, padding = 1\n",
    "    * Sloj 3 - Broj izlaznih kanala = 128, veličina jezgre = 4, veličina koraka = 2, padding = 1\n",
    "    * Sloj 4 - Broj izlaznih kanala = 64, veličina jezgre = 4, veličina koraka = 2, padding = 1\n",
    "    * Sloj 5 - Broj izlaznih kanala = 1, veličina jezgre = 4, veličina koraka = 2, padding = 1\n",
    "\n",
    "* Diskriminator\n",
    "    * Sloj 1 - Broj izlaznih konvolucija = 64, veličina jezgre = 4, veličina koraka = 2, padding = 1\n",
    "    * Sloj 2 - Broj izlaznih konvolucija = 128, veličina jezgre = 4, veličina koraka = 2, padding = 1\n",
    "    * Sloj 3 - Broj izlaznih konvolucija = 256, veličina jezgre = 4, veličina koraka = 2, padding = 1\n",
    "    * Sloj 4 - Broj izlaznih konvolucija = 512, veličina jezgre = 4, veličina koraka = 2, padding = 1\n",
    "    * Sloj 5 - Broj izlaznih konvolucija = 1, veličina jezgre = 4, veličina koraka = 1, padding = 0\n",
    "\n",
    "Ulaz u generator $\\mathbf z$ neka ima 100 elemenata prema normalnoj distribuciji $N(0,1)$. Ulazni podaci neka su MNIST brojevi skalirani na veličinu 64x64 te treniranje provedite kroz barem 20 epoha. U jednoj iteraciji provedite jednu optimizaciju generatora i jednu optimizaciju diskriminatora s po jednom mini grupom. Koristite tanh aktivacijsku funkciju za izlaz generatora i sigmoid aktivaciju za izlaz diskriminator, a za ostaje slojeve \"propustljivi\" ReLU sa \"negative_slope\" parametrom od 0.2. Batch noramlizacija (jedan od podzadataka) ide iza svakog sloja.\n",
    "\n",
    "**Podzadaci:**\n",
    "\n",
    " 1. Vizualizirajte rezultate generiranja 100 novih uzoraka iz slučajnih vektora $\\mathbf z$. Usporedite rezultate s uzorcima generiranim pomoću VAE.\n",
    " 2. Spremite težine istreniranog modela u datoteku \"zad5_gan.th\" i uploadajte tu datoteku na Moodle.\n",
    " 3. Na Moodle predajte vizualizaciju 1. podzadatka.\n",
    " 4. Odgovorite na sljedeća pitanja **u bilježnici**. Bilježnicu na kraju predajte na Moodle.\n",
    "\n",
    "\n",
    "Koristite sljedeći predložak:\n",
    "\n",
    "**NAPOMENA**: Osim nadopunjavanja koda koji nedostaje, predložak se treba prilagođavati prema potrebi, a može i prema vlastitim preferencijama. Stoga **budite oprezni s tvrdnjama da vam neki dio koda ne radi!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ih9ryX_hUtV-"
   },
   "source": [
    "**Pitanje:**\n",
    "    \n",
    "U jednoj iteraciji provedite treniranje diskriminatora sa dvaje minigrupe a generatora sa jednom minigrupom. Ponovite isti postupak samo zamijenite mjesta generatora i diskriminatora. Vizualizirajte generirane uzorke i komentirajte retzultate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kvGOY-yJUtV-"
   },
   "source": [
    "**Odgovor:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dt7SMrWGUtV_"
   },
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wHDdurmNUtV_"
   },
   "source": [
    "**Pitanje:**\n",
    "\n",
    "Isključite batch normalizaciju u obje mreže. Komentirajte rezultate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jWSSH11TUtV_"
   },
   "source": [
    "**Odgovor:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ddaja2QaUtWA"
   },
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 389,
     "status": "ok",
     "timestamp": 1623409643769,
     "user": {
      "displayName": "Filip Todorić",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiH7DuUBhcAqaYzLq0j65wQZ4SfN8adz357E-Tp=s64",
      "userId": "01972315933449635735"
     },
     "user_tz": -120
    },
    "id": "dSAHj36eUtWA"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_size=100):\n",
    "        super(Generator, self).__init__()\n",
    "        self.latent_size = latent_size\n",
    "\n",
    "        self.kernel_size = 4\n",
    "\n",
    "        # Convolutional layers\n",
    "        self.conv1 = torch.nn.ConvTranspose2d(in_channels=latent_size,\n",
    "                                     out_channels=512,\n",
    "                                     kernel_size=self.kernel_size,\n",
    "                                     stride=1,\n",
    "                                     padding=0)\n",
    "        \n",
    "        self.conv2 = torch.nn.ConvTranspose2d(in_channels=512,\n",
    "                                     out_channels=256,\n",
    "                                     kernel_size=self.kernel_size,\n",
    "                                     stride=2,\n",
    "                                     padding=1)\n",
    "        \n",
    "        self.conv3 = torch.nn.ConvTranspose2d(in_channels=256,\n",
    "                                     out_channels=128,\n",
    "                                     kernel_size=self.kernel_size,\n",
    "                                     stride=2,\n",
    "                                     padding=1)\n",
    "        \n",
    "        self.conv4 = torch.nn.ConvTranspose2d(in_channels=128,\n",
    "                                     out_channels=64,\n",
    "                                     kernel_size=self.kernel_size,\n",
    "                                     stride=2,\n",
    "                                     padding=1)\n",
    "        \n",
    "        self.conv5 = torch.nn.ConvTranspose2d(in_channels=64,\n",
    "                                     out_channels=1,\n",
    "                                     kernel_size=self.kernel_size,\n",
    "                                     stride=2,\n",
    "                                     padding=1)\n",
    "        \n",
    "        # Batch normalization layers\n",
    "        self.bnorm1 = torch.nn.BatchNorm2d(num_features=512)\n",
    "        self.bnorm2 = torch.nn.BatchNorm2d(num_features=256)\n",
    "        self.bnorm3 = torch.nn.BatchNorm2d(num_features=128)\n",
    "        self.bnorm4 = torch.nn.BatchNorm2d(num_features=64)\n",
    "        \n",
    "        # ReLu & tanh\n",
    "        self.lrelu = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.tanh = nn.Tanh()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Conv\n",
    "        y = self.conv1(x)\n",
    "        # ReLu\n",
    "        y = self.lrelu(y)\n",
    "        # Batch normalization\n",
    "        y = self.bnorm1(y)\n",
    "\n",
    "        y = self.conv2(y)\n",
    "        y = self.lrelu(y)\n",
    "        y = self.bnorm2(y)\n",
    "        \n",
    "        y = self.conv3(y)\n",
    "        y = self.lrelu(y)\n",
    "        y = self.bnorm3(y)\n",
    "\n",
    "        y = self.conv4(y)\n",
    "        y = self.lrelu(y)\n",
    "        y = self.bnorm4(y)\n",
    "\n",
    "        y = self.conv5(y)\n",
    "        # tanh\n",
    "        return self.tanh(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 363,
     "status": "ok",
     "timestamp": 1623409656447,
     "user": {
      "displayName": "Filip Todorić",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiH7DuUBhcAqaYzLq0j65wQZ4SfN8adz357E-Tp=s64",
      "userId": "01972315933449635735"
     },
     "user_tz": -120
    },
    "id": "qRMWk6CtUtWB"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.kernel_size = 4\n",
    "\n",
    "        # Convolutional layers\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=1,\n",
    "                                     out_channels=64,\n",
    "                                     kernel_size=self.kernel_size,\n",
    "                                     stride=2,\n",
    "                                     padding=1)\n",
    "        \n",
    "        self.conv2 = torch.nn.Conv2d(in_channels=64,\n",
    "                                     out_channels=128,\n",
    "                                     kernel_size=self.kernel_size,\n",
    "                                     stride=2,\n",
    "                                     padding=1)\n",
    "        \n",
    "        self.conv3 = torch.nn.Conv2d(in_channels=128,\n",
    "                                     out_channels=256,\n",
    "                                     kernel_size=self.kernel_size,\n",
    "                                     stride=2,\n",
    "                                     padding=1)\n",
    "        \n",
    "        self.conv4 = torch.nn.Conv2d(in_channels=256,\n",
    "                                     out_channels=512,\n",
    "                                     kernel_size=self.kernel_size,\n",
    "                                     stride=2,\n",
    "                                     padding=1)\n",
    "        \n",
    "        self.conv5 = torch.nn.Conv2d(in_channels=512,\n",
    "                                     out_channels=1,\n",
    "                                     kernel_size=self.kernel_size,\n",
    "                                     stride=1,\n",
    "                                     padding=0)\n",
    "        \n",
    "        # Batch normalization layers\n",
    "        self.bnorm1 = torch.nn.BatchNorm2d(num_features=64)\n",
    "        self.bnorm2 = torch.nn.BatchNorm2d(num_features=128)\n",
    "        self.bnorm3 = torch.nn.BatchNorm2d(num_features=256)\n",
    "        self.bnorm4 = torch.nn.BatchNorm2d(num_features=512)\n",
    "\n",
    "        # ReLu & sigmoid\n",
    "        self.lrelu = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Conv\n",
    "        y = self.conv1(x)\n",
    "        # Relu\n",
    "        y = self.lrelu(y)\n",
    "        # Batch normalization\n",
    "        y = self.bnorm1(y)\n",
    "\n",
    "        y = self.conv2(y)\n",
    "        y = self.lrelu(y)\n",
    "        y = self.bnorm2(y)\n",
    "        \n",
    "        y = self.conv3(y)\n",
    "        y = self.lrelu(y)\n",
    "        y = self.bnorm3(y)\n",
    "\n",
    "        y = self.conv4(y)\n",
    "        y = self.lrelu(y)\n",
    "        y = self.bnorm4(y)\n",
    "\n",
    "        y = self.conv5(y)\n",
    "        out = self.sigmoid(y)\n",
    "        \n",
    "        return out.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1623409656447,
     "user": {
      "displayName": "Filip Todorić",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiH7DuUBhcAqaYzLq0j65wQZ4SfN8adz357E-Tp=s64",
      "userId": "01972315933449635735"
     },
     "user_tz": -120
    },
    "id": "TTYmb0bDUtWB"
   },
   "outputs": [],
   "source": [
    "dmodel = Discriminator()\n",
    "gmodel = Generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1623409656776,
     "user": {
      "displayName": "Filip Todorić",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiH7DuUBhcAqaYzLq0j65wQZ4SfN8adz357E-Tp=s64",
      "userId": "01972315933449635735"
     },
     "user_tz": -120
    },
    "id": "UUbO_EU-UtWC"
   },
   "outputs": [],
   "source": [
    "def train(gmodel: Generator, dmodel: Discriminator, n_epochs=10, log_epochs=1, batch_size=32, learning_rate=1e-3, device='cpu'):\n",
    "    train_loader, test_loader = prepare_data_loaders(batch_size=batch_size)\n",
    "    \n",
    "    gmodel = gmodel.to(device)\n",
    "    dmodel = dmodel.to(device)\n",
    "    \n",
    "    gmodel.train()\n",
    "    dmodel.train()\n",
    "    \n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    g_optim = optim.Adam(gmodel.parameters(), lr=learning_rate)\n",
    "    d_optim = optim.Adam(dmodel.parameters(), lr=learning_rate)\n",
    "    \n",
    "    for epoch_idx in range(0, n_epochs):\n",
    "        \n",
    "        g_loss, d_loss = 0, 0\n",
    "        \n",
    "        for image_data, _ in tqdm.tqdm(train_loader):\n",
    "            # discriminator update\n",
    "            dmodel.zero_grad()\n",
    "            \n",
    "            # real data pass\n",
    "            image_data = image_data.to(device)\n",
    "            \n",
    "            batch_size = image_data.shape[0]\n",
    "            labels = torch.ones(batch_size, device=device).float()\n",
    "            \n",
    "            d_output = dmodel(image_data)\n",
    "            d_err_real = criterion(d_output, labels)\n",
    "            d_err_real.backward()\n",
    "            d_loss += d_err_real.item() / batch_size\n",
    "            \n",
    "            # fake data pass\n",
    "            noise = torch.randn(batch_size, gmodel.latent_size, 1, 1, device=device)\n",
    "            fake_image_data = gmodel(noise)\n",
    "            labels = torch.zeros(batch_size, device=device).float()\n",
    "            \n",
    "            d_output = dmodel(fake_image_data.detach())\n",
    "            d_error_fake = criterion(d_output, labels)\n",
    "            d_error_fake.backward()\n",
    "            d_loss += d_error_fake.item() / batch_size\n",
    "    \n",
    "            d_optim.step()\n",
    "            \n",
    "            # generator update\n",
    "            gmodel.zero_grad()\n",
    "            \n",
    "            labels = torch.ones(batch_size, device=device)\n",
    "            d_output = dmodel(fake_image_data)\n",
    "            g_error = criterion(d_output, labels)\n",
    "            g_error.backward()\n",
    "            g_loss += g_error.item() / batch_size \n",
    "            g_optim.step()\n",
    "            \n",
    "        if (epoch_idx + 1) % log_epochs == 0:\n",
    "            print(f\"[{epoch_idx+1}/{n_epochs}]: d_loss = {d_loss:.2f} g_loss {g_loss:.2f}\")\n",
    "            \n",
    "    gmodel.eval()\n",
    "    dmodel.eval()\n",
    "    \n",
    "    return gmodel, dmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 527204,
     "status": "error",
     "timestamp": 1623410184576,
     "user": {
      "displayName": "Filip Todorić",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiH7DuUBhcAqaYzLq0j65wQZ4SfN8adz357E-Tp=s64",
      "userId": "01972315933449635735"
     },
     "user_tz": -120
    },
    "id": "DZW_SoINUtWC",
    "outputId": "a7032ef1-1d3b-4bec-e6f5-99e7e529c3ed"
   },
   "outputs": [],
   "source": [
    "gmodel, dmodel = train(gmodel, dmodel, n_epochs=20, batch_size=128, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 221,
     "status": "ok",
     "timestamp": 1623410198552,
     "user": {
      "displayName": "Filip Todorić",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiH7DuUBhcAqaYzLq0j65wQZ4SfN8adz357E-Tp=s64",
      "userId": "01972315933449635735"
     },
     "user_tz": -120
    },
    "id": "5RoRdOPAUtWD"
   },
   "outputs": [],
   "source": [
    "random_sample = gmodel(torch.randn(100, 100, 1, 1).to('cuda')).view(100, 64, 64).data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 901
    },
    "executionInfo": {
     "elapsed": 4107,
     "status": "ok",
     "timestamp": 1623410206258,
     "user": {
      "displayName": "Filip Todorić",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiH7DuUBhcAqaYzLq0j65wQZ4SfN8adz357E-Tp=s64",
      "userId": "01972315933449635735"
     },
     "user_tz": -120
    },
    "id": "ZjVxVW97UtWD",
    "outputId": "faeabbc9-5fa3-460d-fae5-de278a2d0bdc"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 16))\n",
    "for idx in range(0, 100):\n",
    "    plt.subplot(10, 10, idx+1)\n",
    "    plt.imshow(random_sample[idx, ...])\n",
    "    plt.clim(0, 1)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 16
    },
    "executionInfo": {
     "elapsed": 225,
     "status": "ok",
     "timestamp": 1623410258029,
     "user": {
      "displayName": "Filip Todorić",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiH7DuUBhcAqaYzLq0j65wQZ4SfN8adz357E-Tp=s64",
      "userId": "01972315933449635735"
     },
     "user_tz": -120
    },
    "id": "NVPz8-Y6UtWD",
    "outputId": "b470c394-adbb-432d-ded4-725411f17808"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "with open('zad5_gan.th', 'wb') as f:\n",
    "    torch.save(gmodel.state_dict(), f)\n",
    "\n",
    "files.download(\"zad5_gan.th\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WXXJ3Z5Tyq5M"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "03-GAN",
   "provenance": [
    {
     "file_id": "1ZUAqIjSU3dKgk-FmMgZ6lIcZ4NLSoNhy",
     "timestamp": 1623360458487
    },
    {
     "file_id": "1wKmQ6vKZwYBHfvW0dy35qTMqCB6AZXQE",
     "timestamp": 1621859720511
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
